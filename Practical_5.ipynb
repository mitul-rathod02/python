{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dFj4aQsj0Kk4",
        "outputId": "b9f86b7b-4856-4a7a-ad98-101c8fdbb136"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokens from Statement 1:\n",
            "['Named', 'Entity', 'Recognition', '(', 'NER', ')', 'is', 'a', 'subtask', 'of', 'NLP', 'that', 'involves', 'identifying', 'proper', 'names', 'in', 'text', '.']\n",
            "\n",
            "Tokens from Statement 2:\n",
            "['For', 'example', ',', 'in', 'the', 'sentence', \"'Apple\", 'Inc.', 'released', 'the', 'new', 'iPhone', 'model', 'in', 'California', ',', \"'\", 'NER', 'would', 'identify', \"'Apple\", 'Inc.', \"'\", 'as', 'an', 'organization', 'and', \"'California\", \"'\", 'as', 'a', 'location', '.']\n"
          ]
        }
      ],
      "source": [
        "# Import the necessary library\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Ensure that you have the required resources\n",
        "# nltk.download('punkt')\n",
        "\n",
        "# Two statements from the paragraph\n",
        "statement1 = \"Named Entity Recognition (NER) is a subtask of NLP that involves identifying proper names in text.\"\n",
        "statement2 = \"For example, in the sentence 'Apple Inc. released the new iPhone model in California,' NER would identify 'Apple Inc.' as an organization and 'California' as a location.\"\n",
        "\n",
        "# Tokenizing the statements\n",
        "tokens1 = word_tokenize(statement1)\n",
        "tokens2 = word_tokenize(statement2)\n",
        "\n",
        "# Printing the results\n",
        "print(\"Tokens from Statement 1:\")\n",
        "print(tokens1)\n",
        "\n",
        "print(\"\\nTokens from Statement 2:\")\n",
        "print(tokens2)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing necessary libraries\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# Ensure that you have the required resources\n",
        "# nltk.download('punkt')\n",
        "# nltk.download('stopwords')\n",
        "\n",
        "# Two statements from the paragraph\n",
        "statement1 = \"Named Entity Recognition (NER) is a subtask of NLP that involves identifying proper names in text.\"\n",
        "statement2 = \"For example, in the sentence 'Apple Inc. released the new iPhone model in California,' NER would identify 'Apple Inc.' as an organization and 'California' as a location.\"\n",
        "\n",
        "# Tokenizing the statements\n",
        "tokens1 = word_tokenize(statement1)\n",
        "tokens2 = word_tokenize(statement2)\n",
        "\n",
        "# Getting the list of English stop words\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# Removing stop words from the tokens\n",
        "filtered_tokens1 = [word for word in tokens1 if word.lower() not in stop_words]\n",
        "filtered_tokens2 = [word for word in tokens2 if word.lower() not in stop_words]\n",
        "\n",
        "# Printing the results\n",
        "print(\"Tokens from Statement 1 without stop words:\")\n",
        "print(filtered_tokens1)\n",
        "\n",
        "print(\"\\nTokens from Statement 2 without stop words:\")\n",
        "print(filtered_tokens2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WSdoleaV0scC",
        "outputId": "864225fb-9d0c-4c4d-bc39-a4e33990f79d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokens from Statement 1 without stop words:\n",
            "['Named', 'Entity', 'Recognition', '(', 'NER', ')', 'subtask', 'NLP', 'involves', 'identifying', 'proper', 'names', 'text', '.']\n",
            "\n",
            "Tokens from Statement 2 without stop words:\n",
            "['example', ',', 'sentence', \"'Apple\", 'Inc.', 'released', 'new', 'iPhone', 'model', 'California', ',', \"'\", 'NER', 'would', 'identify', \"'Apple\", 'Inc.', \"'\", 'organization', \"'California\", \"'\", 'location', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing necessary libraries\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# Ensure that you have the required resources\n",
        "# nltk.download('punkt')\n",
        "# nltk.download('stopwords')\n",
        "\n",
        "# Two statements from the paragraph\n",
        "statement1 = \"Named Entity Recognition (NER) is a subtask of NLP that involves identifying proper names in text.\"\n",
        "statement2 = \"For example, in the sentence 'Apple Inc. released the new iPhone model in California,' NER would identify 'Apple Inc.' as an organization and 'California' as a location.\"\n",
        "\n",
        "# Step 1: Tokenizing the statements\n",
        "tokens1 = word_tokenize(statement1)\n",
        "tokens2 = word_tokenize(statement2)\n",
        "\n",
        "# Printing tokens from both statements\n",
        "print(\"Tokens from Statement 1:\")\n",
        "print(tokens1)\n",
        "\n",
        "print(\"\\n\\nTokens from Statement 2:\")\n",
        "print(tokens2)\n",
        "\n",
        "# Step 2: Getting the list of English stop words\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# Removing stop words from the tokens\n",
        "filtered_tokens1 = [word for word in tokens1 if word.lower() not in stop_words]\n",
        "filtered_tokens2 = [word for word in tokens2 if word.lower() not in stop_words]\n",
        "\n",
        "# Printing the results after removing stop words\n",
        "print(\"\\n\\nTokens from Statement 1 without stop words:\")\n",
        "print(filtered_tokens1)\n",
        "\n",
        "print(\"\\nTokens from Statement 2 without stop words:\")\n",
        "print(filtered_tokens2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w4WjqyVj1FCR",
        "outputId": "f736bc85-8ddf-4140-dbeb-7955bb064ee7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokens from Statement 1:\n",
            "['Named', 'Entity', 'Recognition', '(', 'NER', ')', 'is', 'a', 'subtask', 'of', 'NLP', 'that', 'involves', 'identifying', 'proper', 'names', 'in', 'text', '.']\n",
            "\n",
            "\n",
            "Tokens from Statement 2:\n",
            "['For', 'example', ',', 'in', 'the', 'sentence', \"'Apple\", 'Inc.', 'released', 'the', 'new', 'iPhone', 'model', 'in', 'California', ',', \"'\", 'NER', 'would', 'identify', \"'Apple\", 'Inc.', \"'\", 'as', 'an', 'organization', 'and', \"'California\", \"'\", 'as', 'a', 'location', '.']\n",
            "\n",
            "\n",
            "Tokens from Statement 1 without stop words:\n",
            "['Named', 'Entity', 'Recognition', '(', 'NER', ')', 'subtask', 'NLP', 'involves', 'identifying', 'proper', 'names', 'text', '.']\n",
            "\n",
            "Tokens from Statement 2 without stop words:\n",
            "['example', ',', 'sentence', \"'Apple\", 'Inc.', 'released', 'new', 'iPhone', 'model', 'California', ',', \"'\", 'NER', 'would', 'identify', \"'Apple\", 'Inc.', \"'\", 'organization', \"'California\", \"'\", 'location', '.']\n"
          ]
        }
      ]
    }
  ]
}